{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a750e0",
   "metadata": {},
   "source": [
    "# Model B: Liver Cirrhosis Analysis & Leakage Correction with Optimization\n",
    "본 노트북은 기존 모델의 **Target Leakage(Stage-specific Winsorization)** 문제를 해결하고, \n",
    "신뢰할 수 있는 파이프라인(3-way Split, Optimized Pipeline)을 구축하여 최종 성능을 검증하는 과정을 담고 있습니다.\n",
    "\n",
    "## 주요 목차 (Contents)\n",
    "1.  **EDA (Exploratory Data Analysis)**: Feature 분포 및 Stage별 차이 시각화\n",
    "2.  **Preprocessing & Leakage Fix**: Winsorization 문제점 시각화 및 대안(RobustScaler) 적용\n",
    "3.  **Feature Engineering**: 의학적 비율 변수 생성\n",
    "4.  **Modeling & Tuning**: 과적합 방지를 위한 Regularization & Optuna Tuning\n",
    "5.  **Calibration & Evaluation**: 확률 보정 및 최종 성능 평가\n",
    "6.  **Interpretation**: SHAP을 이용한 중요 변수 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, accuracy_score, classification_report\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "\n",
    "# Visualization Settings\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' # For Windows Korean support\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab30039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "fpath = '../data/liver_cirrhosis_deduped.csv' # 경로 확인 필요\n",
    "df = pd.read_csv(fpath)\n",
    "\n",
    "# Filter Target (1, 2, 3) & Drop ID\n",
    "if 'ID' in df.columns:\n",
    "    df = df.drop('ID', axis=1)\n",
    "    \n",
    "df = df[df['Stage'].isin([1, 2, 3])].copy()\n",
    "target_col = 'Stage'\n",
    "\n",
    "print(f\"Data Shape: {df.shape}\")\n",
    "print(df[target_col].value_counts().sort_index())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355089c",
   "metadata": {},
   "source": [
    "## 1. EDA: Feature Distributions by Stage\n",
    "주요 수치형 변수들이 Stage(1, 2, 3)에 따라 어떻게 분포가 달라지는지 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba655b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_plot = ['Bilirubin', 'Albumin', 'Prothrombin', 'Copper', 'Age', 'Platelets']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(features_to_plot):\n",
    "    if col in df.columns:\n",
    "        sns.boxplot(data=df, x='Stage', y=col, ax=axes[i], palette='viridis')\n",
    "        axes[i].set_title(f'{col} by Stage')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dea668",
   "metadata": {},
   "source": [
    "### 해석\n",
    "*   **Bilirubin**: Stage가 높아질수록 수치가 상승하는 경향이 뚜렷합니다.\n",
    "*   **Albumin**: 간 기능 저하로 인해 Stage 3에서 낮아지는 경향이 보입니다.\n",
    "*   **Platelets (혈소판)**: 간경변이 진행될수록 감소하는 추세입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e78032",
   "metadata": {},
   "source": [
    "## 2. Leakage Diagnosis: Winsorization vs RobustScaler\n",
    "**기존 오류**: Stage별로 이상치를 처리함 -> 정답 정보를 전처리에 사용 (Leakage).\n",
    "**개선안**: 전체 데이터 기준으로 `RobustScaler` 사용 또는 Pipeline 내 처리.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f97ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화: Leakage가 있는 경우 vs 없는 경우의 분포 변화 비교 (가상 예시)\n",
    "\n",
    "# 1. Leakage Case (Stage-specific)\n",
    "df_leak = df.copy()\n",
    "for stage in [1, 2, 3]:\n",
    "    mask = df_leak['Stage'] == stage\n",
    "    q_low = df_leak.loc[mask, 'Bilirubin'].quantile(0.05)\n",
    "    q_high = df_leak.loc[mask, 'Bilirubin'].quantile(0.95)\n",
    "    df_leak.loc[mask, 'Bilirubin'] = df_leak.loc[mask, 'Bilirubin'].clip(q_low, q_high)\n",
    "\n",
    "# 2. Correct Case (Robust Scaler - Global)\n",
    "df_correct = df.copy()\n",
    "rs = RobustScaler()\n",
    "df_correct['Bilirubin'] = rs.fit_transform(df_correct[['Bilirubin']])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.kdeplot(data=df_leak, x='Bilirubin', hue='Stage', fill=True, palette='viridis', ax=ax[0])\n",
    "ax[0].set_title(\"Problem (Leakage): Artificial Separation by Stage-specific Clip\")\n",
    "\n",
    "sns.kdeplot(data=df_correct, x='Bilirubin', hue='Stage', fill=True, palette='viridis', ax=ax[1])\n",
    "ax[1].set_title(\"Correct Model (RobustScaler): Natural Overlap Preserved\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca983b",
   "metadata": {},
   "source": [
    "**왼쪽 그래프(Leakage)**를 보면 Stage별 분포가 인위적으로 모이거나 분리되는 경향이 생길 수 있습니다. 이는 모델이 쉽게 정답을 맞추게 도와줍니다.\n",
    "**오른쪽 그래프(Correct)**는 실제 데이터의 중첩(Overlap)을 그대로 보여주며, 이것이 모델이 풀어야 할 **진짜 난이도**입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7578034",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering & Splitting\n",
    "과적합을 막고 진짜 신호를 찾기 위해 의학적 비율 변수를 추가하고, **3-way Split (Train/Calib/Test)**을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Variable Generation\n",
    "df_eng = df.copy()\n",
    "df_eng['Bili_Alb_Ratio'] = df_eng['Bilirubin'] / (df_eng['Albumin'] + 1e-6)\n",
    "df_eng['SGOT_Platelets_Ratio'] = df_eng['SGOT'] / (df_eng['Platelets'] + 1e-6)\n",
    "df_eng['Age_Decade'] = (df_eng['Age'] / 365.25 / 10).astype(int)\n",
    "\n",
    "# 2. Encoding Target\n",
    "le = LabelEncoder()\n",
    "df_eng['target'] = le.fit_transform(df_eng['Stage']) # 0, 1, 2\n",
    "\n",
    "X = df_eng.drop(['Stage', 'target'], axis=1)\n",
    "y = df_eng['target']\n",
    "\n",
    "# 3. 3-way Split\n",
    "# Train(60%), Calib(20%), Test(20%)\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "train_idx, eval_idx = next(sss1.split(X, y))\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_eval, y_eval = X.iloc[eval_idx], y.iloc[eval_idx]\n",
    "\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "calib_idx, test_idx = next(sss2.split(X_eval, y_eval))\n",
    "X_calib, y_calib = X_eval.iloc[calib_idx], y.iloc[calib_idx]\n",
    "X_test, y_test = X_eval.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Calib: {X_calib.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780969c6",
   "metadata": {},
   "source": [
    "## 4. Optimized Model Training\n",
    "Optuna를 통해 찾은(또는 사전 정의된) **최적 하이퍼파라미터**를 사용하여 과적합을 제어합니다.\n",
    "*   **Key**: `max_depth` 제한, `reg_alpha`(L1) 강화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Params (Example from Phase 2)\n",
    "best_params = {\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.05,\n",
    "    'min_child_weight': 10,\n",
    "    'gamma': 1.0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 5.0,  # Strong L1\n",
    "    'reg_lambda': 5.0  # Strong L2\n",
    "}\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler()) # Robust against outliers\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# XGBoost Pipeline\n",
    "clf = XGBClassifier(\n",
    "    random_state=42, use_label_encoder=False, eval_metric='mlogloss',\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', clf)\n",
    "])\n",
    "\n",
    "print(\"Training Optimized Pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc54b32",
   "metadata": {},
   "source": [
    "## 5. Calibration & Evaluation\n",
    "Calib Set을 사용하여 예측 확률을 보정(Isotonic Regression)하고, Test Set에서 최종 ECE(Calibration Error)를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b348c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Calibration Class (Simplified)\n",
    "class CalibrationWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.calibrators = []\n",
    "        self.classes_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Assume base estimator is already fitted\n",
    "        self.classes_ = self.base_estimator.classes_\n",
    "        raw_probs = self.base_estimator.predict_proba(X)\n",
    "        \n",
    "        for i in range(len(self.classes_)):\n",
    "            y_binary = (y == i).astype(int)\n",
    "            iso = IsotonicRegression(out_of_bounds='clip')\n",
    "            iso.fit(raw_probs[:, i], y_binary)\n",
    "            self.calibrators.append(iso)\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        raw_probs = self.base_estimator.predict_proba(X)\n",
    "        calibrated_probs = np.zeros_like(raw_probs)\n",
    "        for i, cal in enumerate(self.calibrators):\n",
    "            calibrated_probs[:, i] = cal.transform(raw_probs[:, i])\n",
    "        \n",
    "        # Normalize\n",
    "        calibrated_probs /= calibrated_probs.sum(axis=1, keepdims=True)\n",
    "        return calibrated_probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "# Apply Calibration\n",
    "calib_model = CalibrationWrapper(pipeline)\n",
    "calib_model.fit(X_calib, y_calib)\n",
    "\n",
    "# Final Eval\n",
    "y_pred = calib_model.predict(X_test)\n",
    "y_prob = calib_model.predict_proba(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "loss = log_loss(y_test, y_prob)\n",
    "\n",
    "print(f\"Final Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Final Test Log Loss: {loss:.4f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Stage 1', 'Stage 2', 'Stage 3']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b143f19",
   "metadata": {},
   "source": [
    "## 6. Interpretation (SHAP)\n",
    "모델이 어떤 변수를 중요하게 보는지 SHAP Value를 통해 분석합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4484b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Preparation\n",
    "preprocessor = pipeline.named_steps['preprocessor']\n",
    "model = pipeline.named_steps['model']\n",
    "\n",
    "# Transform Test Data for SHAP\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get Feature Names\n",
    "if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "else:\n",
    "    feature_names = [f'f{i}' for i in range(X_test_transformed.shape[1])]\n",
    "\n",
    "# SHAP Explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "# Summary Plot (Class 0 - Stage 1 기준 예시, 또는 전체)\n",
    "print(\"SHAP Summary Plot\")\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
